{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got full_df\n",
      "got parsed_df\n",
      "got full_df\n",
      "got parsed_df\n"
     ]
    }
   ],
   "source": [
    "# do basic imports and unpack McMurdo data\n",
    "\n",
    "from pmagpy import ipmag\n",
    "reload(ipmag)\n",
    "from pmagpy import pmag\n",
    "from programs import new_builder as nb\n",
    "from programs import data_model3\n",
    "reload(data_model3)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from programs.new_builder import Contribution\n",
    "\n",
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-W- No such file: /Users/nebula/Python/PmagPy/3_0/Megiddo/images.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "measurement\n",
       "mgh05a01:LP-PI-TRM0     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM1     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM2     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM3     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM4     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM5     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM6     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM7     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM8     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM9     mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM10    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM11    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM12    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM13    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM14    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM15    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM16    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM17    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM18    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM19    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM20    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM21    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM22    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM23    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM24    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM25    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM26    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM27    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM28    mgh05a01:LP-PI-TRM\n",
       "mgh05a01:LP-PI-TRM29    mgh05a01:LP-PI-TRM\n",
       "                               ...        \n",
       "mgh03g07:LP-AN-TRM3     mgh03g07:LP-AN-TRM\n",
       "mgh03g07:LP-AN-TRM4     mgh03g07:LP-AN-TRM\n",
       "mgh03g07:LP-AN-TRM5     mgh03g07:LP-AN-TRM\n",
       "mgh03g07:LP-AN-TRM6     mgh03g07:LP-AN-TRM\n",
       "mgh03g07:LP-AN-TRM7     mgh03g07:LP-AN-TRM\n",
       "mgh03g07:LP-AN-TRM8     mgh03g07:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM1     mgh03b06:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM2     mgh03b06:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM3     mgh03b06:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM4     mgh03b06:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM5     mgh03b06:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM6     mgh03b06:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM7     mgh03b06:LP-AN-TRM\n",
       "mgh03b06:LP-AN-TRM8     mgh03b06:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM1     mgh03h07:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM2     mgh03h07:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM3     mgh03h07:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM4     mgh03h07:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM5     mgh03h07:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM6     mgh03h07:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM7     mgh03h07:LP-AN-TRM\n",
       "mgh03h07:LP-AN-TRM8     mgh03h07:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM1     mgh03h08:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM2     mgh03h08:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM3     mgh03h08:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM4     mgh03h08:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM5     mgh03h08:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM6     mgh03h08:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM7     mgh03h08:LP-AN-TRM\n",
       "mgh03h08:LP-AN-TRM8     mgh03h08:LP-AN-TRM\n",
       "Name: experiment, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.path.join(os.getcwd(), '3_0', 'Megiddo')\n",
    "con = Contribution(dir_path)\n",
    "\n",
    "loc_dm = con.tables['locations'].data_model.dm['locations']\n",
    "loc_df = con.tables['locations'].df\n",
    "site_dm = con.tables['sites'].data_model.dm['sites']\n",
    "site_df = con.tables['sites'].df\n",
    "samp_df = con.tables['samples'].df\n",
    "samp_dm = con.tables['samples'].data_model.dm['samples']\n",
    "spec_df = con.tables['specimens'].df\n",
    "spec_dm = con.tables['specimens'].data_model.dm['specimens']\n",
    "age_df = con.tables['ages'].df\n",
    "age_dm = con.tables['ages'].data_model.dm['ages']\n",
    "meas_df = con.tables['measurements'].df\n",
    "meas_dm = con.tables['measurements'].data_model.dm['measurements']\n",
    "cont_df = con.tables['contribution'].df\n",
    "cont_dm = con.tables['contribution'].data_model.dm['contribution']\n",
    "crit_df = con.tables['criteria'].df\n",
    "crit_dm = con.tables['criteria'].data_model.dm['criteria']\n",
    "\n",
    "\n",
    "current_con = con\n",
    "\n",
    "# mess up some validations for locations\n",
    "loc_df.loc['Tel Hazor', 'lat_s'] = 400.\n",
    "loc_df['dir_inc'] = 5\n",
    "loc_df.loc['Tel Hazor', 'lat_n'] = 'hello'\n",
    "loc_df.loc[:, 'lithologies'] = [\"Agate\", \"random\"]\n",
    "#current_con.tables.pop('sites')\n",
    "\n",
    "# mess up some validations for sites\n",
    "#site_df.pop('age')\n",
    "#site_df['dir_tilt_correction'] = 1\n",
    "#site_df['dir_tilt_correction'] = 'one'\n",
    "\n",
    "# mess up some validations for samples\n",
    "samp_df.pop('citations')\n",
    "samp_df.iloc[0].lon = 600.\n",
    "samp_df.iloc[0].age = \"another string\"\n",
    "samp_df.iloc[0].lat = \"stringy\"\n",
    "samp_df.iloc[1].lat = 'hello'\n",
    "samp_df.iloc[2].specimens = \"hz05a2:fake\"\n",
    "samp_df.iloc[3].specimens = \"fake : hz05a1\"\n",
    "samp_df.iloc[5].specimens = 'fake_specimen'\n",
    "samp_df.iloc[7].site = 'fake_site'\n",
    "samp_df.iloc[0].cooling_rate = 'a string'\n",
    "\n",
    "# mess up some validations for measurements\n",
    "meas_df.loc['mgh05a01:LP-PI-TRM1', 'magn_moment'] = 2\n",
    "meas_df.loc['mgh05a01:LP-PI-TRM1', 'specimen'] = \"fake_specimen\"\n",
    "meas_df.pop('experiment')\n",
    "\n",
    "#current_df.head()\n",
    "#current_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Importing controlled vocabularies from https://earthref.org\n"
     ]
    }
   ],
   "source": [
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "reload(cv)\n",
    "vocab = cv.Vocabulary()\n",
    "vocabulary, possible_vocabulary = vocab.get_controlled_vocabularies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## validation functions\n",
    "\n",
    "\n",
    "# need to add requiredOneInGroup\n",
    "\n",
    "def requiredUnless(col_name, df, arg, *args):\n",
    "    arg_list = arg.split(\",\")\n",
    "    arg_list = [arg.strip('\"') for arg in arg_list]\n",
    "    msg = \"\"\n",
    "    for a in arg_list:\n",
    "        if \".\" in a:\n",
    "            continue\n",
    "        if a not in df.columns:\n",
    "            msg += \"{} is required unless {} is present.  \".format(col_name, a)\n",
    "    if msg:\n",
    "        return msg\n",
    "    else:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def requiredUnlessTable(col_name, df, arg, *args):\n",
    "    \"\"\"\n",
    "    Col_name must be present in df unless\n",
    "    arg (table_name) is present in contribution\n",
    "    \"\"\"\n",
    "    table_name = arg\n",
    "    if col_name in df.columns:\n",
    "        return None\n",
    "    elif table_name in current_con.tables:\n",
    "        return None\n",
    "    else:\n",
    "        #print \"{} is required unless table {} is present\".format(col_name, table_name)\n",
    "        return \"{} is required unless table {} is present\".format(col_name, table_name)\n",
    "\n",
    "    \n",
    "def requiredIfGroup(col_name, df, arg, *args):\n",
    "    \"\"\"\n",
    "    Col_name is required if other columns of \n",
    "    the group arg are present.\n",
    "    \"\"\"\n",
    "    group_name = arg\n",
    "    groups = set()\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        if col not in current_dm.index:\n",
    "            continue\n",
    "        group = current_dm.loc[col]['group']\n",
    "        groups.add(group)\n",
    "    if group_name in groups:\n",
    "        if col_name in columns:\n",
    "            return None\n",
    "        else:\n",
    "            #print \"{} is required if column group {} is used\".format(col_name, group_name)\n",
    "            return \"{} is required if column group {} is used\".format(col_name, group_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "def required(col_name, df, arg):\n",
    "    if col_name in df.columns:\n",
    "        return None\n",
    "    else:\n",
    "        return \"{} is required\".format(col_name) \n",
    "\n",
    "def isIn(row, col_name, arg, dm, df):\n",
    "    #grade = df.apply(func, args=(validation_name, arg, dm), axis=1)\n",
    "    x = 0\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    # if it's in another table\n",
    "    cell_values = [v.strip(\" \") for v in cell_value.split(\":\")]\n",
    "    if \".\" in arg:\n",
    "        table_name, table_col_name = arg.split(\".\")\n",
    "        if table_name not in current_con.tables:\n",
    "            return \"Must contain a value from {} table. Missing {} table.\".format(table_name, table_name)\n",
    "        if table_col_name not in current_con.tables[table_name].df.columns:\n",
    "            return \"{} table is missing {} column, which is required for validation\".format(table_name, table_col_name)\n",
    "        possible_values = current_con.tables[table_name].df[table_col_name].unique()\n",
    "        for value in cell_values:\n",
    "            if value not in possible_values:\n",
    "                return \"This value: {} is not found in: {}\".format(value, arg)\n",
    "                break\n",
    "    # if it's in the present table:\n",
    "    else:\n",
    "        possible_values = df[arg].unique()\n",
    "        for value in cell_values:\n",
    "            if value not in possible_values:\n",
    "                return \"This value: {} is not found in: {} column\".format(value, arg)\n",
    "                break\n",
    "    return None\n",
    "    \n",
    "def checkMax(row, col_name, arg, *args):\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    try:\n",
    "        arg = float(arg)\n",
    "    except ValueError:\n",
    "        arg = row[arg]\n",
    "    #arg = float(arg)\n",
    "    try:\n",
    "        if float(cell_value) <= float(arg):\n",
    "            return None\n",
    "        else:\n",
    "            #print \"{} must be <= {}\".format(str(cell_value), str(arg))\n",
    "            return \"{} must be <= {}\".format(str(cell_value), str(arg))\n",
    "    # this happens when the value isn't a float (an error which will be caught elsewhere)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def checkMin(row, col_name, arg, *args):\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    try:\n",
    "        arg = float(arg)\n",
    "    except ValueError:\n",
    "        arg = row[arg]\n",
    "    try:\n",
    "        if float(cell_value) >= float(arg):\n",
    "            return None\n",
    "        else:\n",
    "            return \"{} must be >= {}\".format(str(cell_value), str(arg))\n",
    "    # this happens when the value isn't a float (an error which will be caught elsewhere)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def cv(row, col_name, arg, current_data_model, *args):\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    if cell_value.lower() in [v.lower() for v in vocabulary[col_name]]:\n",
    "        return None\n",
    "    else:\n",
    "        return \"{} is not in {}\".format(cell_value, arg)\n",
    "        \n",
    "\n",
    "# validate presence\n",
    "presence_operations = {\"required\": required, \"requiredUnless\": requiredUnless,\n",
    "                       \"requiredIfGroup\": requiredIfGroup, \n",
    "                       'requiredUnlessTable': requiredUnlessTable}\n",
    "# validate values\n",
    "value_operations = {\"max\": checkMax, \"min\": checkMin, \"cv\": cv, \"in\": isIn}\n",
    "\n",
    "def split_func(string):\n",
    "    \"\"\"\n",
    "    Take a string like 'requiredIf(\"arg_name\")'\n",
    "    return the function name and the argument:\n",
    "    (requiredIf, arg_name)\n",
    "    \"\"\"\n",
    "    ind = string.index(\"(\")\n",
    "    return string[:ind], string[ind+1:-1].strip('\"')\n",
    "\n",
    "\n",
    "def test_type(value, value_type):\n",
    "    if not value:\n",
    "        return None\n",
    "    if value_type == \"String\":\n",
    "        if str(value) == value:\n",
    "            return None\n",
    "        else:\n",
    "            return \"should be string\"\n",
    "    elif value_type == \"Number\":\n",
    "        try:\n",
    "            float(value)\n",
    "            return None\n",
    "        except ValueError:\n",
    "            return \"should be a number\"\n",
    "    elif value_type == \"Integer\":\n",
    "        if isinstance(value, str):\n",
    "            if str(int(value)) == value:\n",
    "                return None\n",
    "            else:\n",
    "                return \"should be an integer\"\n",
    "        else:\n",
    "            if int(value) == value:\n",
    "                return None\n",
    "            else:\n",
    "                return \"should be an integer\"\n",
    "    else:\n",
    "        return None\n",
    "    #String, Number, Integer, List, Matrix, Dictionary, Text\n",
    "    \n",
    "\n",
    "\n",
    "def validate_df(df, dm):\n",
    "    # check column validity\n",
    "    cols = df.columns\n",
    "    invalid_cols = [col for col in cols if col not in dm.index]\n",
    "    for validation_name, validation in dm.iterrows():\n",
    "        value_type = validation['type']\n",
    "        if validation_name in df.columns:\n",
    "            output = df[validation_name].apply(test_type, args=(value_type,))\n",
    "            df[\"type_pass\" + \"_\" + validation_name + \"_\" + value_type] = output\n",
    "\n",
    "        val_list = validation['validations']\n",
    "        if not val_list or isinstance(val_list, float):\n",
    "            continue\n",
    "        for num, val in enumerate(val_list):\n",
    "            func_name, arg = split_func(val)\n",
    "            if arg == \"magic_table_column\":\n",
    "                continue\n",
    "            # first validate for presence\n",
    "            if func_name in presence_operations:\n",
    "                func = presence_operations[func_name]\n",
    "                grade = func(validation_name, current_df, arg)\n",
    "                pass_col_name = \"presence_pass_\" + validation_name + \"_\" + func.__name__\n",
    "                df[pass_col_name] = grade\n",
    "    \n",
    "            # then validate for correct values\n",
    "            elif func_name in value_operations:\n",
    "                func = value_operations[func_name]\n",
    "                if validation_name in df.columns:\n",
    "                    grade = df.apply(func, args=(validation_name, arg, dm, df), axis=1)\n",
    "                    col_name = \"value_pass_\" + validation_name + \"_\" + func.__name__\n",
    "                    if col_name in df.columns:\n",
    "                        num_range = range(1, 10)\n",
    "                        for num in num_range:\n",
    "                            if (col_name + str(num)) in df.columns:\n",
    "                                continue\n",
    "                            else:\n",
    "                                col_name = col_name + str(num)\n",
    "                                break\n",
    "                    df[col_name] = grade.astype(object)\n",
    "    return df\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# check that values pass validation\n",
    "# validation checks to add:\n",
    "# sv (suggested vocab)\n",
    "# requiredOneInGroup\n",
    "# requiredUnlessSynthetic\n",
    "\n",
    "\n",
    "# re-do upload_magic to use contribution-level (??)\n",
    "\n",
    "# first, do validations on each table in the contribution\n",
    "# this will include removing unneeded data (RmKeys from old upload_magic)\n",
    "# this will also include checking everything against the data model (strings are strings, etc.)g\n",
    "\n",
    "\n",
    "# next, splat out each table into a file and wrap it up.  give it a sensible name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_df = current_con.tables['samples'].df  \n",
    "current_dm = current_con.tables['samples'].data_model.dm['samples']\n",
    "\n",
    "current_df = validate_df(current_df, current_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_col_names(df):\n",
    "    value_cols = df.columns.str.match(\"^value_pass_\")\n",
    "    present_cols = df.columns.str.match(\"^presence_pass\")\n",
    "    type_cols = df.columns.str.match(\"^type_pass_\")\n",
    "\n",
    "    value_col_names = df.columns[value_cols]\n",
    "    present_col_names = df.columns[present_cols]\n",
    "    type_col_names = df.columns[type_cols]\n",
    "\n",
    "    validation_cols = np.where(value_cols, value_cols, present_cols)\n",
    "    validation_cols = np.where(validation_cols, validation_cols, type_cols)\n",
    "    validation_col_names = df.columns[validation_cols]\n",
    "    return value_col_names, present_col_names, type_col_names, validation_col_names\n",
    "\n",
    "value_col_names, present_col_names, type_col_names, validation_col_names = get_validation_col_names(current_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_pass_cooling_rate_Number</th>\n",
       "      <th>type_pass_lat_Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hz05a</th>\n",
       "      <td>should be a number</td>\n",
       "      <td>should be a number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05a</th>\n",
       "      <td>None</td>\n",
       "      <td>should be a number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05b</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05b</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05c</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type_pass_cooling_rate_Number type_pass_lat_Number\n",
       "sample                                                   \n",
       "hz05a             should be a number   should be a number\n",
       "hz05a                           None   should be a number\n",
       "hz05b                           None                 None\n",
       "hz05b                           None                 None\n",
       "hz05c                           None                 None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# incorrect data type problems\n",
    "current_df[type_col_names].dropna(how='all', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presence_pass_citations_required</th>\n",
       "      <th>presence_pass_result_quality_required</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hz05a</th>\n",
       "      <td>citations is required</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05a</th>\n",
       "      <td>citations is required</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05b</th>\n",
       "      <td>citations is required</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05b</th>\n",
       "      <td>citations is required</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05c</th>\n",
       "      <td>citations is required</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       presence_pass_citations_required presence_pass_result_quality_required\n",
       "sample                                                                       \n",
       "hz05a             citations is required            result_quality is required\n",
       "hz05a             citations is required            result_quality is required\n",
       "hz05b             citations is required            result_quality is required\n",
       "hz05b             citations is required            result_quality is required\n",
       "hz05c             citations is required            result_quality is required"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing column problems\n",
    "current_df[present_col_names].dropna(how='all', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_pass_lon_checkMax</th>\n",
       "      <th>value_pass_site_isIn</th>\n",
       "      <th>value_pass_specimens_isIn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hz05a</th>\n",
       "      <td>600.0 must be &lt;= 360.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05a</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05b</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>This value: fake is not found in: specimens.sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05b</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>This value: fake is not found in: specimens.sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz05c</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value_pass_lon_checkMax value_pass_site_isIn  \\\n",
       "sample                                                \n",
       "hz05a   600.0 must be <= 360.0                 None   \n",
       "hz05a                     None                 None   \n",
       "hz05b                     None                 None   \n",
       "hz05b                     None                 None   \n",
       "hz05c                     None                 None   \n",
       "\n",
       "                                value_pass_specimens_isIn  \n",
       "sample                                                     \n",
       "hz05a                                                None  \n",
       "hz05a                                                None  \n",
       "hz05b   This value: fake is not found in: specimens.sp...  \n",
       "hz05b   This value: fake is not found in: specimens.sp...  \n",
       "hz05c                                                None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value problems:\n",
    "current_df[value_col_names].dropna(how='all', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  return all: \n",
    "#    rows with a problem\n",
    "#    columns with a problem\n",
    "#    cells with a problem\n",
    "#    missing columns\n",
    "#    extra columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem rows (value & type problems)\n",
      "hz05a\n",
      "type: type  |  col name:  cooling_rate  |  error message: should be a number\n",
      "...\n",
      "type: type  |  col name:  lat  |  error message: should be a number\n",
      "...\n",
      "type: value  |  col name:  lon  |  error message: 600.0 must be <= 360.0\n",
      "...\n",
      "---\n",
      "hz05a\n",
      "type: type  |  col name:  lat  |  error message: should be a number\n",
      "...\n",
      "---\n",
      "hz05b\n",
      "type: value  |  col name:  specimens  |  error message: This value: fake is not found in: specimens.specimen\n",
      "...\n",
      "---\n",
      "hz05b\n",
      "type: value  |  col name:  specimens  |  error message: This value: fake is not found in: specimens.specimen\n",
      "...\n",
      "---\n",
      "hz05c\n",
      "type: value  |  col name:  specimens  |  error message: This value: fake_specimen is not found in: specimens.specimen\n",
      "...\n",
      "---\n",
      "hz05e\n",
      "type: value  |  col name:  site  |  error message: This value: fake_site is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh03k\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh05a\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh05b\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh05c\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh05d\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh05e\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh05f\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t101\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t102\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1a1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1b1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1c1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1d1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1e1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1f1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1g1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1h1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1i1\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgh12t1i2\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1a1\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1a2\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1b1\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1b2\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1c1\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1c2\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1d1\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgk09t1d2\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t101\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t102\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t103\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t104\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t105\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t106\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t107\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t108\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t109\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t110\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t111\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t112\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq04t1PI\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t101\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t102\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t103\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t104\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t105\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t106\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t107\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t108\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t109\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t111\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t112\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2a1\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2a2\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2b1\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2b2\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2c2\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2d1\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2d2\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2e1\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2e2\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2f1\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "mgq05t2f2\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def extract_col_name(string):\n",
    "    prefixes = [\"presence_pass_\", \"value_pass_\", \"type_pass_\"]\n",
    "    end = string.rfind(\"_\")\n",
    "    for prefix in prefixes:\n",
    "        if string.startswith(prefix):\n",
    "            return prefix[:-6], string[len(prefix):end]\n",
    "    return string, string\n",
    "\n",
    "\n",
    "def check_row(row):\n",
    "    ind = row[row.notnull()].index\n",
    "    values = row[row.notnull()].values\n",
    "    # to transformation with extract_col_name here???\n",
    "    return zip(ind, values)\n",
    "\n",
    "def get_all_failures(df, value_cols, type_cols):\n",
    "    print \"problem rows (value & type problems)\"\n",
    "    df[\"num\"] = range(len(df))\n",
    "    # get column names for value & type validations\n",
    "    names = value_cols.union(type_cols)\n",
    "    # drop all non validation columns\n",
    "    value_problems = df[names.union([\"num\"])]\n",
    "    failing_items = value_problems.dropna(how=\"all\", subset=names)\n",
    "    failing_items = failing_items.dropna(how=\"all\", axis=1)\n",
    "    # get names of the failing items\n",
    "    bad_items = list(failing_items.index)\n",
    "    # get index numbers of the failing items\n",
    "    bad_indices = list(failing_items[\"num\"])\n",
    "    zip(bad_indices, bad_items)\n",
    "\n",
    "    failing_items['issues'] = failing_items.drop(\"num\", axis=1).apply(check_row, axis=1).values\n",
    "    failing_items[\"issues\"].iloc[0]\n",
    "    # maybe do a transformation in here so that you get \"lon\" instead of \"value_pass_lon_checkMax\"\n",
    "    \n",
    "    for ind, row in failing_items.iterrows():\n",
    "        issues = row[\"issues\"]\n",
    "        print ind\n",
    "        for issue in issues:\n",
    "            issue_type, issue_col = extract_col_name(issue[0])\n",
    "            print \"type:\", issue_type,\n",
    "            print \" | \",\n",
    "            print \"col name: \", issue_col,\n",
    "            print \" | \",\n",
    "            print \"error message:\", issue[1]\n",
    "            print \"...\"\n",
    "        print '---'\n",
    "        \n",
    "get_all_failures(current_df, value_col_names, type_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ages\n",
      "problem rows (value & type problems)\n",
      "13\n",
      "type: value  |  col name:  site  |  error message: This value: mgh05 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "17\n",
      "type: value  |  col name:  site  |  error message: This value: mgh12t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "19\n",
      "type: value  |  col name:  age_high  |  error message: -2800 must be >= -2600\n",
      "...\n",
      "type: value  |  col name:  age_low  |  error message: -2600 must be <= -2800\n",
      "...\n",
      "---\n",
      "20\n",
      "type: value  |  col name:  age_high  |  error message: -1180 must be >= -1130\n",
      "...\n",
      "type: value  |  col name:  age_low  |  error message: -1130 must be <= -1180\n",
      "...\n",
      "---\n",
      "23\n",
      "type: value  |  col name:  site  |  error message: This value: mgk09t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "24\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "25\n",
      "type: value  |  col name:  site  |  error message: This value: mgq04t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "27\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t1 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "28\n",
      "type: value  |  col name:  site  |  error message: This value: mgq05t2 is not found in: sites.site\n",
      "...\n",
      "---\n",
      "sites\n",
      "problem rows (value & type problems)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c467ccfd6651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcurrent_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalue_col_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_col_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_col_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_col_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_validation_col_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mget_all_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_col_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_col_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d440cdaabff2>\u001b[0m in \u001b[0;36mget_all_failures\u001b[0;34m(df, value_cols, type_cols)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mfailing_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'issues'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfailing_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mfailing_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"issues\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# maybe do a transformation in here so that you get \"lon\" instead of \"value_pass_lon_checkMax\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2413\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3351\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3354\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n\u001b[0;32m-> 3454\u001b[0;31m                            placement=slice(loc, loc + 1))\n\u001b[0m\u001b[1;32m   3455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3456\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2459\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[1;32m   2460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2461\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, ndim, fastpath, placement, **kwargs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         super(ObjectBlock, self).__init__(values, ndim=ndim, fastpath=fastpath,\n\u001b[0;32m-> 1610\u001b[0;31m                                           placement=placement, **kwargs)\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[1;32m     82\u001b[0m             raise ValueError('Wrong number of items passed %d, placement '\n\u001b[1;32m     83\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[0;32m---> 84\u001b[0;31m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "## run through and validate entire contribution\n",
    "\n",
    "for dtype in current_con.tables.keys()[1:3]:\n",
    "    print dtype\n",
    "    current_df = current_con.tables[dtype].df\n",
    "    current_dm = current_con.tables[dtype].data_model.dm[dtype]\n",
    "    current_df = validate_df(current_df, current_dm)\n",
    "    value_col_names, present_col_names, type_col_names, validation_col_names = get_validation_col_names(current_df)\n",
    "    get_all_failures(current_df, value_col_names, type_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add in numbered index\n",
    "current_df['num'] = range(len(current_df))\n",
    "# rows with problems:\n",
    "print 'Problem rows (all problems):'\n",
    "\n",
    "problems = current_df[validation_col_names.union([\"num\"])]\n",
    "problems = problems.dropna(how='all', axis=0, subset=validation_col_names)\n",
    "problems = problems.dropna(how='all', axis=1)\n",
    "zip(list(problems[\"num\"]), list(problems.index))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#columns with problems (of ANY type)\n",
    "bad_cols = problems.columns\n",
    "prefixes = [\"value_pass_\", \"type_pass_\"]\n",
    "missing_prefix = \"presence_pass_\"\n",
    "problem_cols = []\n",
    "missing_cols = []\n",
    "for col in bad_cols:\n",
    "    pre, stripped_col = extract_col_name(col)\n",
    "    print col\n",
    "    for prefix in prefixes:\n",
    "        if col.startswith(prefix):\n",
    "            problem_cols.append(stripped_col)\n",
    "            continue\n",
    "    if col.startswith(missing_prefix):\n",
    "        missing_cols.append(stripped_col)\n",
    "\n",
    "print 'Problem columns (wrong type or invalid value):'\n",
    "print problem_cols\n",
    "#\n",
    "print 'Missing columns:'\n",
    "print missing_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in an existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep all of df1, add in any extra from df2\n",
    "df1 = pd.DataFrame(np.random.randint(1, 10, (3, 5)), columns=['one', 'two', 'three', 'four', 'five'])\n",
    "df1.iloc[0, 1] = np.nan\n",
    "df1.iloc[2, 2] = np.nan\n",
    "df2 = pd.DataFrame(np.random.randint(1, 10, (3, 5)), columns=['one', 'three', 'five', 'seven', 'nine'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_df2_cols = df2.columns.difference(df1.columns)\n",
    "unique_df2 = df2[unique_df2_cols]\n",
    "\n",
    "# this adds in all the unique columns that weren't in df1\n",
    "concat_df = pd.concat([df1, unique_df2], axis=1)\n",
    "# fills in null values in df1 with values from df2\n",
    "concat_df.fillna(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
