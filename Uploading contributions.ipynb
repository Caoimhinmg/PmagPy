{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got full_df\n",
      "got parsed_df\n",
      "got full_df\n",
      "got parsed_df\n"
     ]
    }
   ],
   "source": [
    "# do basic imports and unpack McMurdo data\n",
    "\n",
    "#from pmagpy import ipmag\n",
    "#reload(ipmag)\n",
    "from pmagpy import pmag\n",
    "from programs import new_builder as nb\n",
    "from programs import data_model3\n",
    "reload(data_model3)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from programs.new_builder import Contribution\n",
    "\n",
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-W- No such file: /Users/nebula/Python/PmagPy/3_0/Megiddo/images.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_high</th>\n",
       "      <th>age_low</th>\n",
       "      <th>age_unit</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>method_codes</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-740</td>\n",
       "      <td>-732</td>\n",
       "      <td>-800</td>\n",
       "      <td>Years Cal AD (+/-)</td>\n",
       "      <td>\"Tel-Hazor chronology. 2015 revision. Amnon Be...</td>\n",
       "      <td>Tel Hazor</td>\n",
       "      <td>GM-C14:GM-CC-ARCH</td>\n",
       "      <td>hz05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a string</td>\n",
       "      <td>-732</td>\n",
       "      <td>1e+12</td>\n",
       "      <td>Years Cal AD (+/-)</td>\n",
       "      <td>\"Tel-Hazor chronology. 2015 revision. Amnon Be...</td>\n",
       "      <td>Tel Hazor</td>\n",
       "      <td>GM-C14:GM-CC-ARCH</td>\n",
       "      <td>fake site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-850</td>\n",
       "      <td>-800</td>\n",
       "      <td>-900</td>\n",
       "      <td>Years Cal AD (+/-)</td>\n",
       "      <td>\"Tel-Hazor chronology. 2015 revision. Amnon Be...</td>\n",
       "      <td>Tel Hazor</td>\n",
       "      <td>GM-C14:GM-CC-ARCH</td>\n",
       "      <td>hz07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-950</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>Years Cal AD (+/-)</td>\n",
       "      <td>\"Tel-Hazor chronology. 2015 revision. Amnon Be...</td>\n",
       "      <td>Tel Hazor</td>\n",
       "      <td>GM-C14:GM-CC-ARCH</td>\n",
       "      <td>hz09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-950</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>Years Cal AD (+/-)</td>\n",
       "      <td>\"Tel-Hazor chronology. 2015 revision. Amnon Be...</td>\n",
       "      <td>Tel Hazor</td>\n",
       "      <td>GM-C14:GM-CC-ARCH</td>\n",
       "      <td>hz10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age age_high age_low            age_unit  \\\n",
       "0      -740     -732    -800  Years Cal AD (+/-)   \n",
       "1  a string     -732   1e+12  Years Cal AD (+/-)   \n",
       "2      -850     -800    -900  Years Cal AD (+/-)   \n",
       "3      -950     -900   -1000  Years Cal AD (+/-)   \n",
       "4      -950     -900   -1000  Years Cal AD (+/-)   \n",
       "\n",
       "                                         description   location  \\\n",
       "0  \"Tel-Hazor chronology. 2015 revision. Amnon Be...  Tel Hazor   \n",
       "1  \"Tel-Hazor chronology. 2015 revision. Amnon Be...  Tel Hazor   \n",
       "2  \"Tel-Hazor chronology. 2015 revision. Amnon Be...  Tel Hazor   \n",
       "3  \"Tel-Hazor chronology. 2015 revision. Amnon Be...  Tel Hazor   \n",
       "4  \"Tel-Hazor chronology. 2015 revision. Amnon Be...  Tel Hazor   \n",
       "\n",
       "        method_codes       site  \n",
       "0  GM-C14:GM-CC-ARCH       hz05  \n",
       "1  GM-C14:GM-CC-ARCH  fake site  \n",
       "2  GM-C14:GM-CC-ARCH       hz07  \n",
       "3  GM-C14:GM-CC-ARCH       hz09  \n",
       "4  GM-C14:GM-CC-ARCH       hz10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.path.join(os.getcwd(), '3_0', 'Megiddo')\n",
    "con = Contribution(dir_path)\n",
    "\n",
    "loc_dm = con.tables['locations'].data_model.dm['locations']\n",
    "loc_df = con.tables['locations'].df\n",
    "site_dm = con.tables['sites'].data_model.dm['sites']\n",
    "site_df = con.tables['sites'].df\n",
    "samp_df = con.tables['samples'].df\n",
    "samp_dm = con.tables['samples'].data_model.dm['samples']\n",
    "spec_df = con.tables['specimens'].df\n",
    "spec_dm = con.tables['specimens'].data_model.dm['specimens']\n",
    "age_df = con.tables['ages'].df\n",
    "age_dm = con.tables['ages'].data_model.dm['ages']\n",
    "meas_df = con.tables['measurements'].df\n",
    "meas_dm = con.tables['measurements'].data_model.dm['measurements']\n",
    "cont_df = con.tables['contribution'].df\n",
    "cont_dm = con.tables['contribution'].data_model.dm['contribution']\n",
    "crit_df = con.tables['criteria'].df\n",
    "crit_dm = con.tables['criteria'].data_model.dm['criteria']\n",
    "\n",
    "\n",
    "current_con = con\n",
    "\n",
    "# mess up some validations for locations\n",
    "loc_df.loc['Tel Hazor', 'lat_s'] = 400.\n",
    "loc_df['dir_inc'] = 5\n",
    "loc_df.loc['Tel Hazor', 'lat_n'] = 'hello'\n",
    "loc_df.loc[:, 'lithologies'] = [\"Agate:Basalt\", \"Basalt:random\"]\n",
    "#current_con.tables.pop('sites')\n",
    "\n",
    "# mess up some validations for sites\n",
    "site_df.pop('age')\n",
    "site_df['dir_tilt_correction'] = 1\n",
    "site_df['dir_tilt_correction'] = 'one'\n",
    "site_df.iloc[0, list(site_df.columns).index('lithologies')] = \"Angrite:Basalt\"\n",
    "site_df.iloc[1, list(site_df.columns).index('lithologies')] = \"angrite : basalt\"\n",
    "\n",
    "# mess up some validations for ages\n",
    "age_df.ix[1]['age'] = 'a string'\n",
    "age_df.ix[1]['site'] = 'fake site'\n",
    "age_df.ix[1]['age_low'] = 1000000000000.\n",
    "age_df.pop('citations')\n",
    "\n",
    "# mess up some validations for samples\n",
    "samp_df.pop('citations')\n",
    "samp_df.iloc[0].lon = 600.\n",
    "samp_df.iloc[0].age = \"another string\"\n",
    "samp_df.iloc[0].lat = \"stringy\"\n",
    "samp_df.iloc[1].lat = 'hello'\n",
    "samp_df.iloc[2].specimens = \"hz05a2:fake\"\n",
    "samp_df.iloc[3].specimens = \"fake : hz05a1\"\n",
    "samp_df.iloc[5].specimens = 'fake_specimen'\n",
    "samp_df.iloc[7].site = 'fake_site'\n",
    "samp_df.iloc[0].cooling_rate = 'a string'\n",
    "\n",
    "# mess up some validations for measurements\n",
    "meas_df.loc['mgh05a01:LP-PI-TRM1', 'magn_moment'] = 2\n",
    "meas_df.loc['mgh05a01:LP-PI-TRM1', 'specimen'] = \"fake_specimen\"\n",
    "meas_df.pop('experiment')\n",
    "\n",
    "#current_df.head()\n",
    "#current_df.head()\n",
    "age_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-I- Importing controlled vocabularies from https://earthref.org\n"
     ]
    }
   ],
   "source": [
    "import pmagpy.controlled_vocabularies3 as cv\n",
    "reload(cv)\n",
    "vocab = cv.Vocabulary()\n",
    "vocabulary, possible_vocabulary = vocab.get_controlled_vocabularies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## validation functions\n",
    "\n",
    "\n",
    "# need to add requiredOneInGroup\n",
    "\n",
    "def requiredUnless(col_name, df, arg, *args):\n",
    "    \"\"\"\n",
    "    Arg is a string in the format \"str1, str2, ...\"\n",
    "    Each string will be a column name.\n",
    "    Col_name is required in df unless each column from arg is present.\n",
    "    \"\"\"\n",
    "    arg_list = arg.split(\",\")\n",
    "    arg_list = [arg.strip('\"') for arg in arg_list]\n",
    "    msg = \"\"\n",
    "    for a in arg_list:\n",
    "        # ignore validations that reference a different table\n",
    "        if \".\" in a:\n",
    "            continue\n",
    "        if a not in df.columns:\n",
    "            msg += \"{} is required unless {} is present.  \".format(col_name, a)\n",
    "    if msg:\n",
    "        return msg\n",
    "    else:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def requiredUnlessTable(col_name, df, arg, *args):\n",
    "    \"\"\"\n",
    "    Col_name must be present in df unless\n",
    "    arg (table_name) is present in contribution\n",
    "    \"\"\"\n",
    "    table_name = arg\n",
    "    if col_name in df.columns:\n",
    "        return None\n",
    "    elif table_name in current_con.tables:\n",
    "        return None\n",
    "    else:\n",
    "        #print \"{} is required unless table {} is present\".format(col_name, table_name)\n",
    "        return \"{} is required unless table {} is present\".format(col_name, table_name)\n",
    "\n",
    "    \n",
    "def requiredIfGroup(col_name, df, arg, *args):\n",
    "    \"\"\"\n",
    "    Col_name is required if other columns of \n",
    "    the group arg are present.\n",
    "    \"\"\"\n",
    "    group_name = arg\n",
    "    groups = set()\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        if col not in current_dm.index:\n",
    "            continue\n",
    "        group = current_dm.loc[col]['group']\n",
    "        groups.add(group)\n",
    "    if group_name in groups:\n",
    "        if col_name in columns:\n",
    "            return None\n",
    "        else:\n",
    "            #print \"{} is required if column group {} is used\".format(col_name, group_name)\n",
    "            return \"{} is required if column group {} is used\".format(col_name, group_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "def required(col_name, df, arg):\n",
    "    \"\"\"\n",
    "    Col_name is required in df.columns.\n",
    "    Return error message if not.\n",
    "    \"\"\"\n",
    "    if col_name in df.columns:\n",
    "        return None\n",
    "    else:\n",
    "        return \"{} is required\".format(col_name) \n",
    "\n",
    "def isIn(row, col_name, arg, dm, df):\n",
    "    \"\"\"\n",
    "    row[col_name] must contain a value from another column.\n",
    "    If not, return error message.\n",
    "    \"\"\"\n",
    "    #grade = df.apply(func, args=(validation_name, arg, dm), axis=1)\n",
    "    x = 0\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    # if it's in another table\n",
    "    cell_values = [v.strip(\" \") for v in cell_value.split(\":\")]\n",
    "    if \".\" in arg:\n",
    "        table_name, table_col_name = arg.split(\".\")\n",
    "        if table_name not in current_con.tables:\n",
    "            return \"Must contain a value from {} table. Missing {} table.\".format(table_name, table_name)\n",
    "        if table_col_name not in current_con.tables[table_name].df.columns:\n",
    "            return \"{} table is missing {} column, which is required for validation\".format(table_name, table_col_name)\n",
    "        possible_values = current_con.tables[table_name].df[table_col_name].unique()\n",
    "        for value in cell_values:\n",
    "            if value not in possible_values:\n",
    "                return \"This value: {} is not found in: {}\".format(value, arg)\n",
    "                break\n",
    "    # if it's in the present table:\n",
    "    else:\n",
    "        possible_values = df[arg].unique()\n",
    "        for value in cell_values:\n",
    "            if value not in possible_values:\n",
    "                return \"This value: {} is not found in: {} column\".format(value, arg)\n",
    "                break\n",
    "    return None\n",
    "    \n",
    "def checkMax(row, col_name, arg, *args):\n",
    "    \"\"\"\n",
    "    row[col_name] must be less than or equal to arg.\n",
    "    else, return error message.\n",
    "    \"\"\"\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    try:\n",
    "        arg = float(arg)\n",
    "    except ValueError:\n",
    "        arg = row[arg]\n",
    "    #arg = float(arg)\n",
    "    try:\n",
    "        if float(cell_value) <= float(arg):\n",
    "            return None\n",
    "        else:\n",
    "            #print \"{} must be <= {}\".format(str(cell_value), str(arg))\n",
    "            return \"{} must be <= {}\".format(str(cell_value), str(arg))\n",
    "    # this happens when the value isn't a float (an error which will be caught elsewhere)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def checkMin(row, col_name, arg, *args):\n",
    "    \"\"\"\n",
    "    row[col_name] must be greater than or equal to arg.\n",
    "    else, return error message.\n",
    "    \"\"\"\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    try:\n",
    "        arg = float(arg)\n",
    "    except ValueError:\n",
    "        arg = row[arg]\n",
    "    try:\n",
    "        if float(cell_value) >= float(arg):\n",
    "            return None\n",
    "        else:\n",
    "            return \"{} must be >= {}\".format(str(cell_value), str(arg))\n",
    "    # this happens when the value isn't a float (an error which will be caught elsewhere)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def cv(row, col_name, arg, current_data_model, *args):\n",
    "    \"\"\"\n",
    "    row[col_name] must contain only values from the appropriate controlled vocabulary\n",
    "    \"\"\"\n",
    "    print 'calling cv'\n",
    "    cell_value = row[col_name]\n",
    "    if not cell_value:\n",
    "        return None\n",
    "    cell_values = cell_value.split(\":\")\n",
    "    cell_values = [c.strip() for c in cell_values]\n",
    "    for value in cell_values:\n",
    "        if value.lower() in [v.lower() for v in vocabulary[col_name]]:\n",
    "            continue\n",
    "        else:\n",
    "            return \"{} is not in controlled vocabulary for {}\".format(value, arg)\n",
    "    return None\n",
    "        \n",
    "\n",
    "# validate presence\n",
    "presence_operations = {\"required\": required, \"requiredUnless\": requiredUnless,\n",
    "                       \"requiredIfGroup\": requiredIfGroup, \n",
    "                       'requiredUnlessTable': requiredUnlessTable}\n",
    "# validate values\n",
    "value_operations = {\"max\": checkMax, \"min\": checkMin, \"cv\": cv, \"in\": isIn}\n",
    "\n",
    "def split_func(string):\n",
    "    \"\"\"\n",
    "    Take a string like 'requiredIf(\"arg_name\")'\n",
    "    return the function name and the argument:\n",
    "    (requiredIf, arg_name)\n",
    "    \"\"\"\n",
    "    ind = string.index(\"(\")\n",
    "    return string[:ind], string[ind+1:-1].strip('\"')\n",
    "\n",
    "\n",
    "def test_type(value, value_type):\n",
    "    if not value:\n",
    "        return None\n",
    "    if value_type == \"String\":\n",
    "        if str(value) == value:\n",
    "            return None\n",
    "        else:\n",
    "            return \"should be string\"\n",
    "    elif value_type == \"Number\":\n",
    "        try:\n",
    "            float(value)\n",
    "            return None\n",
    "        except ValueError:\n",
    "            return \"should be a number\"\n",
    "    elif value_type == \"Integer\":\n",
    "        if isinstance(value, str):\n",
    "            if str(int(value)) == value:\n",
    "                return None\n",
    "            else:\n",
    "                return \"should be an integer\"\n",
    "        else:\n",
    "            if int(value) == value:\n",
    "                return None\n",
    "            else:\n",
    "                return \"should be an integer\"\n",
    "    else:\n",
    "        return None\n",
    "    #String, Number, Integer, List, Matrix, Dictionary, Text\n",
    "    \n",
    "\n",
    "\n",
    "def validate_df(df, dm):\n",
    "    # check column validity\n",
    "    cols = df.columns\n",
    "    invalid_cols = [col for col in cols if col not in dm.index]\n",
    "    for validation_name, validation in dm.iterrows():\n",
    "        value_type = validation['type']\n",
    "        if validation_name in df.columns:\n",
    "            output = df[validation_name].apply(test_type, args=(value_type,))\n",
    "            df[\"type_pass\" + \"_\" + validation_name + \"_\" + value_type] = output\n",
    "\n",
    "        val_list = validation['validations']\n",
    "        if not val_list or isinstance(val_list, float):\n",
    "            continue\n",
    "        for num, val in enumerate(val_list):\n",
    "            func_name, arg = split_func(val)\n",
    "            if arg == \"magic_table_column\":\n",
    "                continue\n",
    "            # first validate for presence\n",
    "            if func_name in presence_operations:\n",
    "                func = presence_operations[func_name]\n",
    "                grade = func(validation_name, current_df, arg)\n",
    "                pass_col_name = \"presence_pass_\" + validation_name + \"_\" + func.__name__\n",
    "                df[pass_col_name] = grade\n",
    "    \n",
    "            # then validate for correct values\n",
    "            elif func_name in value_operations:\n",
    "                func = value_operations[func_name]\n",
    "                if validation_name in df.columns:\n",
    "                    grade = df.apply(func, args=(validation_name, arg, dm, df), axis=1)\n",
    "                    col_name = \"value_pass_\" + validation_name + \"_\" + func.__name__\n",
    "                    if col_name in df.columns:\n",
    "                        num_range = range(1, 10)\n",
    "                        for num in num_range:\n",
    "                            if (col_name + str(num)) in df.columns:\n",
    "                                continue\n",
    "                            else:\n",
    "                                col_name = col_name + str(num)\n",
    "                                break\n",
    "                    df[col_name] = grade.astype(object)\n",
    "    return df\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# check that values pass validation\n",
    "# validation checks to add:\n",
    "# sv (suggested vocab)\n",
    "# requiredOneInGroup\n",
    "# requiredUnlessSynthetic\n",
    "\n",
    "\n",
    "# re-do upload_magic to use contribution-level (??)\n",
    "\n",
    "# first, do validations on each table in the contribution\n",
    "# this will include removing unneeded data (RmKeys from old upload_magic)\n",
    "# this will also include checking everything against the data model (strings are strings, etc.)g\n",
    "\n",
    "\n",
    "# next, splat out each table into a file and wrap it up.  give it a sensible name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n"
     ]
    }
   ],
   "source": [
    "current_df = current_con.tables['sites'].df  \n",
    "current_dm = current_con.tables['sites'].data_model.dm['sites']\n",
    "\n",
    "current_df = validate_df(current_df, current_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'presence_pass_age_requiredUnless',\n",
       "       u'presence_pass_age_high_requiredUnless',\n",
       "       u'presence_pass_age_low_requiredUnless',\n",
       "       u'presence_pass_age_unit_required',\n",
       "       u'presence_pass_aniso_tilt_correction_requiredIfGroup',\n",
       "       u'presence_pass_aniso_type_requiredIfGroup',\n",
       "       u'presence_pass_citations_required',\n",
       "       u'presence_pass_dir_dec_requiredIfGroup',\n",
       "       u'presence_pass_dir_inc_requiredIfGroup',\n",
       "       u'presence_pass_dir_tilt_correction_requiredIfGroup',\n",
       "       u'presence_pass_geologic_classes_required',\n",
       "       u'presence_pass_geologic_types_required', u'presence_pass_lat_required',\n",
       "       u'presence_pass_lithologies_required',\n",
       "       u'presence_pass_location_required', u'presence_pass_lon_required',\n",
       "       u'presence_pass_method_codes_required',\n",
       "       u'presence_pass_paleo_lat_requiredIfGroup',\n",
       "       u'presence_pass_paleo_lon_requiredIfGroup',\n",
       "       u'presence_pass_result_quality_required',\n",
       "       u'presence_pass_result_type_required', u'presence_pass_site_required',\n",
       "       u'presence_pass_vadm_requiredIfGroup',\n",
       "       u'presence_pass_vdm_requiredIfGroup',\n",
       "       u'presence_pass_vgp_lat_requiredIfGroup',\n",
       "       u'presence_pass_vgp_lon_requiredIfGroup'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_validation_col_names(df):\n",
    "    value_cols = df.columns.str.match(\"^value_pass_\")\n",
    "    present_cols = df.columns.str.match(\"^presence_pass\")\n",
    "    type_cols = df.columns.str.match(\"^type_pass_\")\n",
    "\n",
    "    value_col_names = df.columns[value_cols]\n",
    "    present_col_names = df.columns[present_cols]\n",
    "    type_col_names = df.columns[type_cols]\n",
    "\n",
    "    validation_cols = np.where(value_cols, value_cols, present_cols)\n",
    "    validation_cols = np.where(validation_cols, validation_cols, type_cols)\n",
    "    validation_col_names = df.columns[validation_cols]\n",
    "    return value_col_names, present_col_names, type_col_names, validation_col_names\n",
    "\n",
    "value_col_names, present_col_names, type_col_names, validation_col_names = get_validation_col_names(current_df)\n",
    "present_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_pass_dir_tilt_correction_Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hz05</th>\n",
       "      <td>should be a number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz06</th>\n",
       "      <td>should be a number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz07</th>\n",
       "      <td>should be a number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz09</th>\n",
       "      <td>should be a number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz10</th>\n",
       "      <td>should be a number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type_pass_dir_tilt_correction_Number\n",
       "site                                     \n",
       "hz05                   should be a number\n",
       "hz06                   should be a number\n",
       "hz07                   should be a number\n",
       "hz09                   should be a number\n",
       "hz10                   should be a number"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# incorrect data type problems\n",
    "current_df[type_col_names].dropna(how='all', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presence_pass_age_high_requiredUnless</th>\n",
       "      <th>presence_pass_age_low_requiredUnless</th>\n",
       "      <th>presence_pass_result_quality_required</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hz05</th>\n",
       "      <td>age_high is required unless age is present.</td>\n",
       "      <td>age_low is required unless age is present.</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz06</th>\n",
       "      <td>age_high is required unless age is present.</td>\n",
       "      <td>age_low is required unless age is present.</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz07</th>\n",
       "      <td>age_high is required unless age is present.</td>\n",
       "      <td>age_low is required unless age is present.</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz09</th>\n",
       "      <td>age_high is required unless age is present.</td>\n",
       "      <td>age_low is required unless age is present.</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz10</th>\n",
       "      <td>age_high is required unless age is present.</td>\n",
       "      <td>age_low is required unless age is present.</td>\n",
       "      <td>result_quality is required</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              presence_pass_age_high_requiredUnless  \\\n",
       "site                                                  \n",
       "hz05  age_high is required unless age is present.     \n",
       "hz06  age_high is required unless age is present.     \n",
       "hz07  age_high is required unless age is present.     \n",
       "hz09  age_high is required unless age is present.     \n",
       "hz10  age_high is required unless age is present.     \n",
       "\n",
       "              presence_pass_age_low_requiredUnless  \\\n",
       "site                                                 \n",
       "hz05  age_low is required unless age is present.     \n",
       "hz06  age_low is required unless age is present.     \n",
       "hz07  age_low is required unless age is present.     \n",
       "hz09  age_low is required unless age is present.     \n",
       "hz10  age_low is required unless age is present.     \n",
       "\n",
       "     presence_pass_result_quality_required  \n",
       "site                                        \n",
       "hz05            result_quality is required  \n",
       "hz06            result_quality is required  \n",
       "hz07            result_quality is required  \n",
       "hz09            result_quality is required  \n",
       "hz10            result_quality is required  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing column problems\n",
    "current_df[present_col_names].dropna(how='all', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_pass_age_high_checkMin</th>\n",
       "      <th>value_pass_age_low_checkMax</th>\n",
       "      <th>value_pass_criteria_isIn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hz05</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz06</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz07</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz09</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hz10</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     value_pass_age_high_checkMin value_pass_age_low_checkMax  \\\n",
       "site                                                            \n",
       "hz05                         None                        None   \n",
       "hz06                         None                        None   \n",
       "hz07                         None                        None   \n",
       "hz09                         None                        None   \n",
       "hz10                         None                        None   \n",
       "\n",
       "     value_pass_criteria_isIn  \n",
       "site                           \n",
       "hz05                     None  \n",
       "hz06                     None  \n",
       "hz07                     None  \n",
       "hz09                     None  \n",
       "hz10                     None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value problems:\n",
    "current_df[value_col_names].dropna(how='all', axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "canopy_exercise": {
     "cell_type": "<None>"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_col_name(string):\n",
    "    prefixes = [\"presence_pass_\", \"value_pass_\", \"type_pass_\"]\n",
    "    end = string.rfind(\"_\")\n",
    "    for prefix in prefixes:\n",
    "        if string.startswith(prefix):\n",
    "            return prefix[:-6], string[len(prefix):end]\n",
    "    return string, string\n",
    "\n",
    "\n",
    "def check_row(row):\n",
    "    ind = row[row.notnull()].index\n",
    "    values = row[row.notnull()].values\n",
    "    # to transformation with extract_col_name here???\n",
    "    return dict(zip(ind, values))\n",
    "\n",
    "#def check_row(row):\n",
    "#    return True\n",
    "\n",
    "def get_all_failures(df, value_cols, type_cols):\n",
    "    print \"problem rows (value & type problems)\"\n",
    "    df[\"num\"] = range(len(df))\n",
    "    # get column names for value & type validations\n",
    "    names = value_cols.union(type_cols)\n",
    "    # drop all non validation columns\n",
    "    value_problems = df[names.union([\"num\"])]\n",
    "    failing_items = value_problems.dropna(how=\"all\", subset=names)\n",
    "    if not len(failing_items):\n",
    "        print \"No problems\"\n",
    "        return\n",
    "    failing_items = failing_items.dropna(how=\"all\", axis=1)\n",
    "    # get names of the failing items\n",
    "    bad_items = list(failing_items.index)\n",
    "    # get index numbers of the failing items\n",
    "    bad_indices = list(failing_items[\"num\"])\n",
    "    zip(bad_indices, bad_items)\n",
    "    #failing_items.drop(\"num\", axis=1, inplace=True)#.apply(check_row, axis=1).values\n",
    "    failing_items['issues'] = failing_items.drop(\"num\", axis=1).apply(check_row, axis=1).values\n",
    "    # maybe do a transformation in here so that you get \"lon\" instead of \"value_pass_lon_checkMax\"\n",
    "    \n",
    "    for ind, row in failing_items.iterrows():\n",
    "        issues = row[\"issues\"]\n",
    "        print ind, row[\"num\"]\n",
    "        for key, issue in issues.items():\n",
    "            issue_type, issue_col = extract_col_name(key)\n",
    "            print \"type: {:10}\".format(issue_type), \n",
    "            print \" | \",\n",
    "            print \"col name: {:10}\".format(issue_col),\n",
    "            print \" | \",\n",
    "            print \"error message:\", issue\n",
    "            print \"...\"\n",
    "        print '---'\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_bad_rows_and_cols(df, validation_names):\n",
    "    df[\"num\"] = range(len(df))\n",
    "    problems = df[validation_col_names.union([\"num\"])]\n",
    "    problems = problems.dropna(how='all', axis=0, subset=validation_names)\n",
    "    problems = problems.dropna(how='all', axis=1)\n",
    "    if not len(problems):\n",
    "        return None, None, None\n",
    "    bad_rows = zip(list(problems[\"num\"]), list(problems.index))\n",
    "    #\n",
    "    bad_cols = problems.columns\n",
    "    prefixes = [\"value_pass_\", \"type_pass_\"]\n",
    "    missing_prefix = \"presence_pass_\"\n",
    "    problem_cols = []\n",
    "    missing_cols = []\n",
    "    for col in bad_cols:\n",
    "        pre, stripped_col = extract_col_name(col)\n",
    "        for prefix in prefixes:\n",
    "            if col.startswith(prefix):\n",
    "                problem_cols.append(stripped_col)\n",
    "                continue\n",
    "        if col.startswith(missing_prefix):\n",
    "            missing_cols.append(stripped_col)\n",
    "    return bad_rows, problem_cols, missing_cols\n",
    "    \n",
    "#a, b, c = get_bad_rows_and_cols(current_df, validation_col_names)\n",
    "#if a:\n",
    "#    print \"bad rows:\", a[:10]\n",
    "#    print \"problems:\", b[:10]\n",
    "#    print \"missing:\", c[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locations\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "calling cv\n",
      "problem rows (value & type problems)\n",
      "Tel Hazor 0\n",
      "type: value       |  col name: lat_s       |  error message: 400.0 must be <= 90.0\n",
      "...\n",
      "type: value       |  col name: lat_s       |  error message: 400.0 must be <= 90.0\n",
      "...\n",
      "type: type        |  col name: lat_n       |  error message: should be a number\n",
      "...\n",
      "type: value       |  col name: lat_s       |  error message: 400.0 must be <= 90.0\n",
      "...\n",
      "---\n",
      "Tel Megiddo 1\n",
      "type: value       |  col name: lithologies  |  error message: random is not in controlled vocabulary for lithology\n",
      "...\n",
      "type: value       |  col name: lithologies  |  error message: random is not in controlled vocabulary for lithology\n",
      "...\n",
      "type: value       |  col name: lithologies  |  error message: random is not in controlled vocabulary for lithology\n",
      "...\n",
      "---\n",
      "*7*7*7\n",
      "these rows have problems: [(0, 'Tel Hazor'), (1, 'Tel Megiddo')]\n",
      "!!!\n",
      "these columns contain bad values: [u'lat_n', u'lat_s', u'lat_s', u'lat_s', u'lithologies', u'lithologies', u'lithologies']\n",
      "!!!\n",
      "these required columns are missing: [u'age_high', u'age_low', u'age', u'age_unit', u'dir_dec', u'dir_tilt_correction', u'geologic_classes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations</th>\n",
       "      <th>lat_n</th>\n",
       "      <th>lat_s</th>\n",
       "      <th>location</th>\n",
       "      <th>location_type</th>\n",
       "      <th>lon_e</th>\n",
       "      <th>lon_w</th>\n",
       "      <th>dir_inc</th>\n",
       "      <th>lithologies</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tel Hazor</th>\n",
       "      <td>This study</td>\n",
       "      <td>hello</td>\n",
       "      <td>400</td>\n",
       "      <td>Tel Hazor</td>\n",
       "      <td>Archeological Site</td>\n",
       "      <td>35.568</td>\n",
       "      <td>35.568</td>\n",
       "      <td>5</td>\n",
       "      <td>Agate:Basalt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tel Megiddo</th>\n",
       "      <td>This study</td>\n",
       "      <td>32.585</td>\n",
       "      <td>32.585</td>\n",
       "      <td>Tel Megiddo</td>\n",
       "      <td>Archeological Site</td>\n",
       "      <td>35.185</td>\n",
       "      <td>35.185</td>\n",
       "      <td>5</td>\n",
       "      <td>Basalt:random</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              citations   lat_n   lat_s     location       location_type  \\\n",
       "location                                                                   \n",
       "Tel Hazor    This study   hello     400    Tel Hazor  Archeological Site   \n",
       "Tel Megiddo  This study  32.585  32.585  Tel Megiddo  Archeological Site   \n",
       "\n",
       "              lon_e   lon_w  dir_inc    lithologies  num  \n",
       "location                                                  \n",
       "Tel Hazor    35.568  35.568        5   Agate:Basalt    0  \n",
       "Tel Megiddo  35.185  35.185        5  Basalt:random    1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run through and validate entire contribution\n",
    "\n",
    "for dtype in current_con.tables.keys()[:]:\n",
    "    print dtype\n",
    "    # grab dataframe\n",
    "    current_df = current_con.tables[dtype].df\n",
    "    # grab data model\n",
    "    current_dm = current_con.tables[dtype].data_model.dm[dtype]\n",
    "    # run all validations (will add columns to current_df)\n",
    "    current_df = validate_df(current_df, current_dm)\n",
    "    # get names of the added columns\n",
    "    value_col_names, present_col_names, type_col_names, validation_col_names = get_validation_col_names(current_df)\n",
    "    # print out failure messages\n",
    "    get_all_failures(current_df, value_col_names, type_col_names)\n",
    "    print '*7*7*7'\n",
    "    bad_rows, bad_cols, missing_cols = get_bad_rows_and_cols(current_df, validation_col_names)\n",
    "    print \"these rows have problems:\", bad_rows\n",
    "    print \"!!!\"\n",
    "    print \"these columns contain bad values:\", bad_cols\n",
    "    print \"!!!\"\n",
    "    print \"these required columns are missing:\", missing_cols\n",
    "    # delete all validation rows\n",
    "    current_df.drop(validation_col_names, axis=1, inplace=True)\n",
    "current_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in an existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  two  three  four  five\n",
       "0    2  NaN    8.0     6     7\n",
       "1    1  1.0    3.0     4     9\n",
       "2    7  3.0    NaN     7     9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep all of df1, add in any extra from df2\n",
    "df1 = pd.DataFrame(np.random.randint(1, 10, (3, 5)), columns=['one', 'two', 'three', 'four', 'five'])\n",
    "df1.iloc[0, 1] = np.nan\n",
    "df1.iloc[2, 2] = np.nan\n",
    "df2 = pd.DataFrame(np.random.randint(1, 10, (3, 5)), columns=['one', 'three', 'five', 'seven', 'nine'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>three</th>\n",
       "      <th>five</th>\n",
       "      <th>seven</th>\n",
       "      <th>nine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  three  five  seven  nine\n",
       "0    5      3     7      2     7\n",
       "1    2      7     1      5     3\n",
       "2    1      8     6      1     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "      <th>nine</th>\n",
       "      <th>seven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  two  three  four  five  nine  seven\n",
       "0    2  NaN    8.0     6     7     7      2\n",
       "1    1  1.0    3.0     4     9     3      5\n",
       "2    7  3.0    8.0     7     9     1      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df2_cols = df2.columns.difference(df1.columns)\n",
    "unique_df2 = df2[unique_df2_cols]\n",
    "\n",
    "# this adds in all the unique columns that weren't in df1\n",
    "concat_df = pd.concat([df1, unique_df2], axis=1)\n",
    "# fills in null values in df1 with values from df2\n",
    "concat_df.fillna(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
