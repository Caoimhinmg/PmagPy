{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nebula/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got full_df\n",
      "got parsed_df\n"
     ]
    }
   ],
   "source": [
    "# do basic imports and unpack McMurdo data\n",
    "\n",
    "from pmagpy import ipmag\n",
    "from pmagpy import pmag\n",
    "from programs import new_builder as nb\n",
    "from programs import data_model3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from programs.new_builder import Contribution\n",
    "\n",
    "wdir = os.path.join(os.getcwd(), \"3_0\", \"McMurdo\")\n",
    "#infile = os.path.join(wdir, \"lawrence09.v30.txt\")\n",
    "#ipmag.download_magic(infile, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Several ways of creating a contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-W- No such file: /Users/nebula/Python/PmagPy/3_0/McMurdo/locations.txt\n",
      "tables created: ['measurements', 'ages', 'sites', 'samples', 'criteria', 'images', 'contribution', 'specimens']\n",
      "-\n",
      "-W- No such file: /Users/nebula/Python/PmagPy/3_0/McMurdo/locations.txt\n",
      "tables created: ['measurements', 'ages', 'sites', 'samples', 'criteria', 'images', 'contribution', 'specimens']\n",
      "-\n",
      "tables created: ['specimens']\n",
      "-\n",
      "tables created: ['sites']\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "reload(nb)\n",
    "\n",
    "# test out various ways of creating a contribution\n",
    "\n",
    "#class Contribution(object):\n",
    "#    \"\"\"                                                                                                                   \n",
    "#    A Contribution is a collection of MagicDataFrames,                                                                    \n",
    "#    each of which corresponds to one MagIC table.                                                                         \n",
    "#    The Contribution object also has methods for                                                                          \n",
    "#    manipulating one or more tables in the contribution --                                                                \n",
    "#    for example, renaming a site.                                                                                         \n",
    "#    \"\"\"\n",
    "#    def __init__(self, directory, read_tables='all',\n",
    "#                 custom_filenames=None, single_file=None):\n",
    "\n",
    "\n",
    "\n",
    "# make contribution reading in all default filenames from working directory\n",
    "con = nb.Contribution(wdir)\n",
    "print 'tables created:', con.tables.keys()\n",
    "print '-'\n",
    "\n",
    "# make contribution with some custom filenames\n",
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt'})\n",
    "print 'tables created:', con.tables.keys()\n",
    "print '-'\n",
    "\n",
    "# make contribution with custom filenames, and only read in the specimen table to start\n",
    "con = Contribution(wdir, read_tables=['specimens'], custom_filenames={'sites': 'custom_sites.txt',\n",
    "                                                                      'specimens': 'custom_specimens.txt'})\n",
    "print 'tables created:', con.tables.keys()\n",
    "print '-'\n",
    "\n",
    "# make contribution with a single, mystery file (can be any datatype)\n",
    "con = nb.Contribution(wdir, single_file='sites.txt')\n",
    "print 'tables created:', con.tables.keys()\n",
    "print '-'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'measurements': 'measurements.txt', 'ages': 'ages.txt', 'sites': 'custom_sites.txt', 'locations': 'locations.txt', 'samples': 'custom_samples.txt', 'criteria': 'criteria.txt', 'images': 'images.txt', 'contribution': 'contribution.txt', 'specimens': 'custom_specimens.txt'}\n",
      "['specimens']\n"
     ]
    }
   ],
   "source": [
    "# make McMurdo contribution, starting with specimens table\n",
    "\n",
    "reload(nb)\n",
    "\n",
    "con = nb.Contribution(wdir, read_tables=['specimens'], custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                                                         'sites': 'custom_sites.txt'})\n",
    "\n",
    "print con.filenames\n",
    "print con.tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['specimens', 'samples']\n"
     ]
    }
   ],
   "source": [
    "# then, add another table to the contribution\n",
    "# here, we are providing data type but no filename\n",
    "# this works because we already gave the custom sample filename when we created the contribution\n",
    "# so the contribution already knows where to look (con.filenames)\n",
    "con.add_magic_table('samples')\n",
    "print con.tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['specimens', 'samples', 'criteria']\n"
     ]
    }
   ],
   "source": [
    "# add another table to the same contribution\n",
    "# this time, provide a filename but no data type\n",
    "\n",
    "con.add_magic_table(dtype=\"unknown\", fname=\"criteria.txt\")\n",
    "# criteria table now included\n",
    "print con.tables.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functionality with a contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-W- No such file: /Users/nebula/Python/PmagPy/3_0/McMurdo/locations.txt\n"
     ]
    }
   ],
   "source": [
    "# create full McMurdo contribution\n",
    "\n",
    "reload(nb)\n",
    "\n",
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                             'sites': 'custom_sites.txt'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'locations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f37df2e6456a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sites'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'locations'"
     ]
    }
   ],
   "source": [
    "con.tables['locations'].df[['sites']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename an item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(nb)\n",
    "# rename one of the Contribution's sites\n",
    "con.rename_item('sites', 'mc01', 'extra_special_site')\n",
    "con.tables['sites'].df.ix[['extra_special_site']]\n",
    "# all rows previously named 'mc01' are now named 'extra_special_site'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# additionally, 'mc01' has been replaced in the location table under site_names\n",
    "#con.tables['locations'].df.ix[[\"Osler Volcanics, Nipigon Strait, Lower Reversed\"]][['site_names']]\n",
    "con.tables['locations'].df[['sites']]#, 'sites_list']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagate data from one table into another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# normally, each table only has one relationship up (i.e., a measurement table will have specimen name, but not sample name)\n",
    "# sometimes, you need to access location_name at the site level (for example)\n",
    "# this function propagates names down through any available tables\n",
    "# the code snippet below won't work if the Contribution can't access the sample and site files!\n",
    "\n",
    "\n",
    "reload(nb)\n",
    "\n",
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                             'sites': 'custom_sites.txt'})\n",
    "\n",
    "con.propagate_name_down('location', 'specimens')\n",
    "\n",
    "# specimens table now has sample, site, and location_names\n",
    "con.tables['specimens'].df[['specimen', 'sample', 'site', 'location']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this function propagates values from arbitrary columns down\n",
    "# i.e., get sample-level azimuth into the measurements table\n",
    "# note: this will NOT work with names (specimen_name, sample_name, etc.).  \n",
    "# for those relationships, use the above function: propagate_name_down\n",
    "\n",
    "reload(nb)\n",
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                             'sites': 'custom_sites.txt'})\n",
    "\n",
    "meas_container = con.tables['measurements']\n",
    "meas_df = meas_container.df\n",
    "\n",
    "meas_df = con.propagate_cols_down(['azimuth', 'dip', 'fake_col'], 'measurements', 'samples')\n",
    "meas_df.head()[['azimuth', 'dip']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out a MagIC file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                             'sites': 'custom_sites.txt'})\n",
    "site_container = con.tables['sites']\n",
    "site_container.write_magic_file(custom_name='fancy_sites.txt', dir_path='./3_0/McMurdo')\n",
    "\n",
    "site_container.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "site_container.df.index.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mucking around with measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                             'sites': 'custom_sites.txt'})\n",
    "\n",
    "meas_container = con.tables['measurements']\n",
    "meas_data = meas_container.df\n",
    "\n",
    "meas_data['treatment'] = meas_data['treat_ac_field'].where(cond=meas_data['treat_ac_field'] != \"0\", other=meas_data['treat_temp'])\n",
    "meas_data[['treatment', 'treat_ac_field', 'treat_temp']]\n",
    "\n",
    "meas_data['treat_ac_field'].ix[0] = None\n",
    "meas_data['treat_ac_field'] = meas_data['treat_ac_field'].astype(float)\n",
    "\n",
    "meas_data[['treatment', 'treat_ac_field', 'treat_temp']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  grab a copy of the criteria and sites table to play with\n",
    "criteria = con.tables['criteria'].df.copy()\n",
    "sites = con.tables['sites'].df.copy()\n",
    "locations = con.tables['locations'].df.copy()\n",
    "specimens = con.tables['specimens'].df.copy()\n",
    "samples = con.tables['samples'].df.copy()\n",
    "sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all criteria for sites\n",
    "\n",
    "# only criteria with 'site' in table_column_name\n",
    "cond = criteria.index.str.contains('site')\n",
    "site_crit = criteria[cond].copy()\n",
    "# remove table name from index\n",
    "site_crit.index = site_crit.index.str.replace('sites.', '')\n",
    "site_crit.index.name = 'column_name'\n",
    "\n",
    "\n",
    "cols = site_crit.index\n",
    "list(cols)\n",
    "cols = list(cols)\n",
    "cols.append('criteria_names')\n",
    "site_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sites.head()[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create string --> operator conversion    \n",
    "import operator\n",
    "ops = {\"<\": operator.lt, \">\": operator.gt, \"==\": operator.eq, \"<=\": operator.le, \">=\": operator.gt}\n",
    "\n",
    "# function for applying criteria\n",
    "def apply_crit(series, crit_series, criteria_type):\n",
    "    \"\"\"\n",
    "    Apply 1 criterion (i.e., 1 row of the criteria table) to another table.\n",
    "    Return series with boolean values for whether the row passes.\n",
    "    \"\"\"\n",
    "    col_name = crit_series.name\n",
    "    #print col_name\n",
    "    # if there's no value, pass == True??  or == False?\n",
    "    if not series[col_name]:\n",
    "        return \"{} not in row\".format(col_name)\n",
    "    # if we're missing criteria names, then what??\n",
    "    elif not series['criteria_names']:\n",
    "        return \"no value in criteria_names\"\n",
    "    elif criteria_type not in series['criteria_names']:\n",
    "        return \"{} not in criteria_names for this row\".format(criteria_type)\n",
    "    crit_name = crit_series['criterion']\n",
    "    crit_value = float(crit_series['criterion_value'])\n",
    "    op_str = crit_series['criterion_operation']\n",
    "    op = ops[op_str]\n",
    "    value = float(series[col_name])\n",
    "    #print value, op_str, crit_value\n",
    "    result = op(value, crit_value)\n",
    "    #print op\n",
    "    #print result\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply a criterion to a table\n",
    "crit_name = 'dir_alpha95'\n",
    "pass_name = 'pass_' + crit_name\n",
    "crit1 = site_crit.ix[crit_name]\n",
    "sites[pass_name] = sites.apply(apply_crit, axis=1, args=(crit1, 'DE-SITE'))\n",
    "cond = sites[pass_name] == True\n",
    "sites[cond][[crit_name, pass_name]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for crit_name in site_crit.index[1:]:\n",
    "    crit_series = site_crit.ix[crit_name]\n",
    "    # if there are multiple records for a single crit_name, ignore that one\n",
    "    if not isinstance(crit_series, pd.Series):\n",
    "        continue\n",
    "    sites['pass_' + crit_name] = sites.apply(apply_crit, axis=1, args=(crit_series, \"DE-SITE\"))\n",
    "\n",
    "    \n",
    "cond = sites.columns.str.contains('pass')\n",
    "sites.head()\n",
    "sites[sites.columns[cond]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create full McMurdo contribution\n",
    "\n",
    "reload(nb)\n",
    "\n",
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                             'sites': 'custom_sites.txt'})\n",
    "\n",
    "\n",
    "criteria = con.tables['criteria'].df.copy()\n",
    "\n",
    "\n",
    "#criteria\n",
    "#print 'criteria_names' in specimens.columns\n",
    "#print 'criteria_names' in samples.columns\n",
    "#print 'criteria_names' in sites.columns\n",
    "#print 'criteria_names' in locations.columns\n",
    "#sites[['criteria_names']]\n",
    "\n",
    "\n",
    "def apply_crit(series, crit_series):#, criteria_type):\n",
    "    \"\"\"\n",
    "    Apply 1 criterion (i.e., 1 row of the criteria table) to another table.\n",
    "    Return series with boolean values for whether the row passes.\n",
    "    \"\"\"\n",
    "    col_name = crit_series.name\n",
    "    # if there's no value, pass == True\n",
    "    if not series[col_name]:\n",
    "        return True\n",
    "        #return \"{} not in row\".format(col_name)\n",
    "    # if there is a value, test that it is within correct limits\n",
    "    crit_name = crit_series['criterion']\n",
    "    crit_value = float(crit_series['criterion_value'])\n",
    "    op_str = crit_series['criterion_operation']\n",
    "    op = ops[op_str]\n",
    "    value = float(series[col_name])\n",
    "    result = op(value, crit_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def add_criteria_named(category_name, dtype):\n",
    "    df = con.tables[dtype].df\n",
    "    criteria_subset = criteria[criteria['criterion'] == category_name]\n",
    "    criteria_subset.index = criteria_subset.index.str.replace(dtype + '.', '')\n",
    "    pass_col_names = []\n",
    "    for crit_name, crit_row in criteria_subset.iterrows():\n",
    "        #print 'crit_name', crit_name\n",
    "        col_name = category_name + \"_\" + crit_name + \"_pass\"\n",
    "        #print 'col_name', col_name\n",
    "        pass_col_names.append(col_name)\n",
    "        df[col_name] = df.apply(apply_crit, args=(crit_row,), axis=1)\n",
    "    return pass_col_names\n",
    "    \n",
    "\n",
    "#DE_SPEC = criteria[criteria['criterion'] == 'DE-SPEC']\n",
    "#DE_SPEC.index = DE_SPEC.index.str.replace('specimens.', '')\n",
    "#pass_col_names = []\n",
    "#for crit_name, crit_row in DE_SPEC.iterrows():\n",
    "#    #print 'crit_name', crit_name\n",
    "#    col_name = 'DE-SPEC_' + crit_name + \"_pass\"\n",
    "#    #print 'col_name', col_name\n",
    "#    pass_col_names.append(col_name)\n",
    "#    specimens[col_name] = specimens.apply(apply_crit, args=(crit_row,), axis=1)\n",
    "    \n",
    "    \n",
    "#specimens_container = con.tables['specimens']\n",
    "dtype = 'specimens'\n",
    "criteria_name = 'IE-SPEC'\n",
    "pass_col = criteria_name + \"_pass\"\n",
    "pass_col_names = add_criteria_named(criteria_name, dtype)\n",
    "df = con.tables[dtype].df\n",
    "\n",
    "#df.ix[:, 13:]\n",
    "col_names = df.columns[df.columns.str.contains(criteria_name)]\n",
    "df[df[col_names].all(1)].head()#[col_names]\n",
    "\n",
    "#cond1 = df[pass_col_names[0]]\n",
    "#cond2 = df[pass_col_names[1]]\n",
    "#cond3 = df[pass_col_names[2]]\n",
    "\n",
    "#cond = cond1 & cond2 & cond3\n",
    "#df[pass_col] = cond\n",
    "\n",
    "## all specimens that pass all DE-SPEC criteria\n",
    "#df[df[pass_col]].index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(nb)\n",
    "import pmagpy.pmag\n",
    "reload(pmagpy.pmag)\n",
    "con = nb.Contribution(wdir, custom_filenames={'specimens': 'custom_specimens.txt', 'samples': 'custom_samples.txt',\n",
    "                                                                         'sites': 'custom_sites.txt'})\n",
    "\n",
    "\n",
    "\n",
    "con.tables['ages'].df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm sites.txt samples.txt specimens.txt measurements.txt ages.txt contribution.txt images.txt criteria.txt locations.txt\n",
    "!rm *.png\n",
    "!rm *.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
